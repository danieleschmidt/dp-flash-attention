name: üêõ Bug Report
description: Report a bug or unexpected behavior in DP-Flash-Attention
title: "[Bug]: "
labels: ["bug", "triage"]
assignees: []
body:
  - type: markdown
    attributes:
      value: |
        Thanks for taking the time to report a bug! Please fill out this form as completely as possible.

  - type: checkboxes
    id: checklist
    attributes:
      label: Pre-flight Checklist
      description: Please confirm you have completed the following
      options:
        - label: I have searched existing issues to ensure this is not a duplicate
          required: true
        - label: I have read the [Contributing Guidelines](https://github.com/yourusername/dp-flash-attention/blob/main/CONTRIBUTING.md)
          required: true
        - label: I have verified this issue exists in the latest version
          required: true

  - type: dropdown
    id: bug-type
    attributes:
      label: Bug Type
      description: What type of bug is this?
      options:
        - Privacy Guarantee Violation
        - Performance Issue
        - CUDA/GPU Error
        - Installation Problem
        - Documentation Issue
        - API/Interface Bug
        - Other
    validations:
      required: true

  - type: textarea
    id: description
    attributes:
      label: Bug Description
      description: A clear and concise description of what the bug is
      placeholder: Describe the bug...
    validations:
      required: true

  - type: textarea
    id: reproduction
    attributes:
      label: Steps to Reproduce
      description: Detailed steps to reproduce the behavior
      placeholder: |
        1. Import dp_flash_attention
        2. Create DPFlashAttention with parameters...
        3. Run forward pass with input...
        4. See error
    validations:
      required: true

  - type: textarea
    id: expected
    attributes:
      label: Expected Behavior
      description: What you expected to happen
      placeholder: Describe what should have happened...
    validations:
      required: true

  - type: textarea
    id: actual
    attributes:
      label: Actual Behavior
      description: What actually happened
      placeholder: Describe what actually happened...
    validations:
      required: true

  - type: textarea
    id: code
    attributes:
      label: Minimal Code Example
      description: Minimal code that reproduces the issue
      render: python
      placeholder: |
        import torch
        from dp_flash_attention import DPFlashAttention
        
        # Your minimal reproduction code here
    validations:
      required: false

  - type: textarea
    id: error
    attributes:
      label: Error Output
      description: Full error traceback (if applicable)
      render: text
      placeholder: Paste the full error traceback here...
    validations:
      required: false

  - type: textarea
    id: environment
    attributes:
      label: Environment Information
      description: |
        Please run: `python -c "import sys, torch, dp_flash_attention; print(f'Python: {sys.version}'); print(f'PyTorch: {torch.__version__}'); print(f'CUDA: {torch.version.cuda}'); print(f'DP-Flash-Attention: {dp_flash_attention.__version__}')"`
      render: text
      placeholder: |
        Python: 3.10.12
        PyTorch: 2.3.0+cu121
        CUDA: 12.1
        DP-Flash-Attention: 0.1.0
        OS: Ubuntu 22.04
        GPU: NVIDIA H100 80GB
    validations:
      required: true

  - type: dropdown
    id: privacy-sensitive
    attributes:
      label: Privacy Sensitivity
      description: Does this bug potentially affect privacy guarantees?
      options:
        - "No - This is not privacy-related"
        - "Yes - This could affect privacy guarantees"
        - "Unsure - Needs privacy team review"
    validations:
      required: true

  - type: textarea
    id: context
    attributes:
      label: Additional Context
      description: Any other context about the problem
      placeholder: Add any other context, screenshots, or relevant information...
    validations:
      required: false

  - type: checkboxes
    id: privacy-confirm
    attributes:
      label: Privacy Confirmation
      description: For privacy-sensitive bugs
      options:
        - label: I confirm this report does not contain sensitive data or model weights
        - label: I understand privacy-related bugs will be handled with additional security measures